---
title: "Part3_Prediction_Model"
author: "Ilse van Beelen"
date: "11/12/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
```


```{r}

set.seed(19950306)

# Load libraries
rm(list = ls())
library(ggplot2)
library(lme4)
library(tidyverse)
library(nlme)
library(emmeans)
library(car)
library(lattice)

theme <-  theme(
              axis.text=element_text(size=15),
              axis.title=element_text(size=22),
              plot.title = element_text(size = 22),
              strip.text = element_text(size = 15),
              legend.title = element_blank())


df_long <- read.csv("Data/data_final_2019-11-05.csv", sep = ",")

# Some data wrangling
df_long <- df_long %>% 
  mutate(hads_tot = hads_depr + hads_anx) %>%
  select(id, ndi, time, hads_tot, hads_anx, hads_depr) %>%
  mutate(ndi = as.numeric(ndi), time = as.numeric(time),
         hads_tot = as.numeric(hads_tot), time_fct = as.factor(time))
  

# Create new dataframe with HADS at time = 0 & NDI at time = 0
df_time0 <- df_long[df_long$time == 0, ]
df_time0 <- select(df_time0, id, ndi, hads_tot, hads_anx, hads_depr)
colnames(df_time0) <-  c("id", "ndi0", "hads0_tot", "hads0_anx", "hads0_depr")

# Create new dataframe with HADS and NDI at 52 and 104 weeks
df_time1_2 <- df_long[df_long$time != 0, ]
df_time1_2 <- select(df_time1_2, id, ndi, time_fct)
colnames(df_time1_2) <-  c("id", "ndi1_2", "time_fct")

# Merge dataframes
df_prediction <- merge(df_time1_2, df_time0, by = "id")

```


# Prediction Model

We fit the following prediction model. It turns out that Time is not significant, therefore we remove this variable. Note that the models below are fitting with Maximum Likelihood (ML)

$$NDI_{i1,i2} = \beta_0 + \beta_1 HADS_{i0} + \beta_2 NDI_{i0} + \beta_3 Time_{i1, i2} + b_{i0} + \varepsilon_{i1, i2} \\
i = 1,2,3, \ldots, 109$$

```{r}

model_pred1 <- lmer(ndi1_2 ~ ndi0 + hads0_anx + hads0_depr + time_fct + (1|id), 
                    data = df_prediction, REML = F)

summary(model_pred1)

```



# Cross validation

Final model is fitted with REML

```{r}

model_final <- lmer(ndi1_2 ~ ndi0 + hads0_anx + hads0_depr + time_fct + (1|id), 
                    data = df_prediction, REML = T)

summary(model_final)


```

Below we divide the data in 5 folds. Should we round the predictions to 0 digits?

```{r}

# Create folds
K <- 5
index <- rep(1:K, floor(nrow(df_prediction)/K)+1)[1:nrow(df_prediction)]
fold.index <- sample(index)


# Create Loss function: Root Mean Squard Error
Loss <- function(x, y){
  mse <- sum((x-y)^2)/length(x)
  rmse <- sqrt(mse)
  return(rmse)
}

loss <- numeric(K)

for (k in 1:K){
  training <- df_prediction[fold.index!=k, ]
  validation <- df_prediction[fold.index==k, ]
  training.fit <- model_final
  
  validation.predict <- predict(training.fit, newdata=validation, type='response')
  loss[k] <- Loss(validation$ndi1_2, validation.predict)
}

loss
round(mean(loss), digits = 1)

```


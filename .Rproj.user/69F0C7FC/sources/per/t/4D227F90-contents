rm(list=ls())
#### importing packages ####
library(GGally)
library(leaps)
library(ggplot2)
library(foreign)
library(gridExtra)
library(leaps)
library(MASS)
library(glmnet)

set.seed(1996) # reproducability

theme_set(theme_classic())

#### reading in data and first split ####
housing <- read.table("data.txt", header = T)
#housing <- read.csv("~/Downloads/housing-p.data.txt", sep="")
housing <- as.data.frame(housing)
housing_test <- housing[c(1:349),]
housing_train <- housing[c(350:nrow(housing)),]


#### data exploration ####

housing$CHAS <- as.numeric(housing$CHAS)
housing$RAD <- as.numeric(housing$RAD)
housing$TAX <- as.numeric(housing$TAX)

summary(housing)

p1 <- ggplot(data=housing, aes(CRIM)) + geom_histogram()
p2 <- ggplot(data=housing, aes(ZN)) + geom_histogram()
p3 <- ggplot(data=housing, aes(INDUS)) + geom_histogram()
p4 <- ggplot(data=housing, aes(CHAS)) + geom_histogram()

grid.arrange(p1, p2, p3, p4, nrow=2)

p5 <- ggplot(data=housing, aes(NOX)) + geom_histogram()
p6 <- ggplot(data=housing, aes(RM)) + geom_histogram()
p7 <- ggplot(data=housing, aes(AGE)) + geom_histogram()
p8 <- ggplot(data=housing, aes(DIS)) + geom_histogram()

grid.arrange(p5, p6, p7, p8, nrow=2)

p9 <- ggplot(data=housing, aes(RAD)) + geom_histogram()
p10 <- ggplot(data=housing, aes(TAX)) + geom_histogram()
p11 <- ggplot(data=housing, aes(PTRATIO)) + geom_histogram()
p12 <- ggplot(data=housing, aes(B)) + geom_histogram()

grid.arrange(p9, p10, p11, p12, nrow=2)

p13 <- ggplot(data=housing, aes(LSTAT)) + geom_histogram()
p14 <- ggplot(data=housing, aes(MEDV)) + geom_histogram()

grid.arrange(p13, p14, nrow=1)

ggcorr(housing)

p15 <- ggplot(data=housing, aes(CRIM, MEDV)) + geom_point()
p16 <- ggplot(data=housing, aes(ZN, MEDV)) + geom_point()
p17 <- ggplot(data=housing, aes(INDUS, MEDV)) + geom_point()
p18 <- ggplot(data=housing, aes(CHAS, MEDV)) + geom_point()

grid.arrange(p15, p16, p17, p18, nrow=2)

p19 <- ggplot(data=housing, aes(NOX, MEDV)) + geom_point()
p20 <- ggplot(data=housing, aes(RM, MEDV)) + geom_point()
p21 <- ggplot(data=housing, aes(AGE, MEDV)) + geom_point()
p22 <- ggplot(data=housing, aes(DIS, MEDV)) + geom_point()

grid.arrange(p19, p20, p21, p22, nrow=2)


p23 <- ggplot(data=housing, aes(RAD, MEDV)) + geom_point()
p24 <- ggplot(data=housing, aes(TAX, MEDV)) + geom_point()
p25 <- ggplot(data=housing, aes(PTRATIO, MEDV)) + geom_point()
p26 <- ggplot(data=housing, aes(B, MEDV)) + geom_point()

grid.arrange(p23, p24, p25, p26, nrow=2)


p27 <- ggplot(data=housing, aes(LSTAT, MEDV)) + geom_point()

p27
#### Linear Model ####

model1 <- lm(MEDV ~ ., data=housing_train)
summary(model1)

p1model1 <- ggplot(model1, aes(.fitted, .resid)) + geom_point() + stat_smooth(method="loess") + geom_hline(yintercept=0, col="red")
p2model1 <- ggplot(model1, aes(sample=.resid)) + stat_qq() + stat_qq_line(col="red")
p2model1

#### CV Linear model ####

folds <- 5
index <- rep(1:folds, floor(nrow(housing)/folds)+1)[1:nrow(housing)]
fold.index <- sample(index)

MSE <- function(x, y){
  sum((x-y)^2)/length(x)
}

train_loss <- numeric(folds)
test_loss <- numeric(folds)

for (k in 1:folds){
  training <- housing[fold.index!=k, ]
  testing <- housing[fold.index==k, ]
  
  training.fit <- lm(MEDV~., data=training)
  testing.predict <- predict(training.fit, newdata=testing, type='response')
  training.predict <- predict(training.fit, newdata=training, type='response')
  train_loss[k] <- MSE(training$MEDV, training.predict)
  test_loss[k] <- MSE(testing$MEDV, testing.predict)
}
mean(train_loss)
mean(test_loss)


#### Subset Search ####

model2 = regsubsets(MEDV ~ ., data=housing_train, nvmax=13) 
model2.summary = summary(model2)

rsq <- as.data.frame(model2.summary$rsq)
rss <- as.data.frame(model2.summary$rss)
names(rsq) <- "Rsquared"
names(rss) <- "RSS"

p1model2 <- ggplot(rsq, aes(x=c(1:13), y=Rsquared)) + geom_point() +labs(x = "Number of Attributes")
p2model2 <- ggplot(rss, aes(x=c(1:13), y=RSS)) + geom_point() +labs(x = "Number of Attributes")

grid.arrange(p1model2, p2model2, nrow=1)


#### CV subset Search ####

folds = 5

predict.subset = function(object, data, id, ...){
  formula = as.formula(object$call[[2]])
  modelm = model.matrix(formula, data)
  coef_ = coef(object, id=id)
  xvariables = names(coef_)
  modelm[,xvariables] %*% coef_
}

sss_train_loss <- matrix(NA,folds, 13, dimnames= list(NULL, paste(1:13)))
sss_test_loss <- matrix(NA, folds, 13, dimnames= list(NULL, paste(1:13)))

for (k in 1:folds){
  training <- housing[fold.index!=k, ]
  testing <- housing[fold.index==k, ]
  
  best <- regsubsets(MEDV~., data=training, nvmax=13)
  
  for (i in 1:13){
    prediction = predict.subset(best, testing, id=i)
    predictiontrain = predict.subset(best, training, id=i)
    sss_train_loss[k, i] = mean((training$MEDV - predictiontrain)^2)
    sss_test_loss[k, i] = mean((testing$MEDV - prediction)^2)
  }
}

sss_train_errors = apply(sss_train_loss, 2, mean)
sss_train_errors = as.data.frame(sss_train_errors)
sss_test_errors = apply(sss_test_loss, 2, mean)
sss_test_errors = as.data.frame(sss_test_errors)

p1model3 <- ggplot(sss_train_errors, aes(x=c(1:13), y=sss_train_errors)) +
  geom_point()+labs(x = "Number of Attributes") + geom_point(aes(x=11, y=21.72451), colour="red")
p2model3 <- ggplot(sss_test_errors, aes(x=c(1:13), y=sss_test_errors)) + 
  geom_point()+labs(x = "Number of Attributes") + geom_point(aes())

p2model3 + geom_point(aes(x=11, y=min(sss_test_errors)), colour="red")

best_model <- regsubsets(MEDV~., data=housing, nvmax=13)
coef(best_model, 11)


model3.pred <- predict.subset(model3, data=housing_test)
mean((model3.pred-housing_test$MEDV)^2)


#### RIDGE  #### 


ridge_x = model.matrix(MEDV~., housing_test)
ridge_y = housing_test %>% dplyr::select(MEDV) %>% unlist() %>% as.numeric()

grid = 10^seq(-2, 3, by=0.01)

model4 <-  cv.glmnet(ridge_x, ridge_y, alpha = 0, lambda = grid, nfolds = 5)
plot(model4)

optimal_lamb <- model4$lambda.1se
optimal_lamb

model4_best <- model4$glmnet.fit
model4_best

ridge_test = model.matrix(MEDV~., housing_test)
model4_pred <- predict(model4_best, s= optimal_lamb, newx = ridge_test)
model4_mse <- mean((model4_pred-housing_test[,c(14)])^2)
model4_mse

#### LASSO ####

lasso_x = model.matrix(MEDV~., housing_test)
lasso_y = housing_test %>% dplyr::select(MEDV) %>% unlist() %>% as.numeric()

model5 <- cv.glmnet(lasso_x, lasso_y, alpha = 1, lambda = grid)

optimal_lamb5 <- model5$lambda.min
optimal_lamb5

model5_best <- model5$glmnet.fit
model5_best

lasso_test = model.matrix(MEDV~., housing_test)

model5_pred <- predict(model5_best, s= optimal_lamb5, newx = lasso_test)
model5_mse <- mean((model4_pred-housing_test[,c(14)])^2)
model5_mse

form <- as.formula(model$call [[2]])
mat <- model.matrix(form,new_data)
coefi <- coef(model ,id=id)
xvars <- names(coefi)
result <- mat[,xvars]%*%coefi
return(result)
}
mse_train_subset <- matrix(NA,K, 13, dimnames=list(NULL, paste(1:16)))
mse_test_subset <- matrix(NA,K, 13, dimnames=list(NULL, paste(1:16)))
mse_train_subset <- matrix(NA,K, 16, dimnames=list(NULL, paste(1:16)))
mse_test_subset <- matrix(NA,K, 16, dimnames=list(NULL, paste(1:16)))
mse_train_subset <- matrix(NA,K, 16, dimnames=list(NULL, paste(1:16)))
mse_test_subset <- matrix(NA,K, 16, dimnames=list(NULL, paste(1:16)))
for(k in 1:K){
training <- data[fold.index!=k, ]
testing <- data[fold.index==k, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = df_train, nvmax = 16)
for (i in 1:13){
pred <-  prediction_subsets(best_fit, testing, id = i)
pred_train <- prediction_subsets(best_fit, training, id=i)
mse_train_subset[k, i] <-  mean((training$ndi1_2 - pred_train)^2)
mse_test_subset[k, i] <-  mean((testing$ndi1_2 - pred)^2)
}
}
K <- 5
index <- rep(1:K, floor(nrow(df_pred_lm)/K)+1)[1:nrow(df_pred_lm)]
fold.index <- sample(index)
model_subset <- regsubsets(ndi1_2 ~ ., data = df_train, nvmax = 16)
summary(model_subset)
# Get some fun statistics: adjusted R-squared, MSE
summary(model_subset)$adjr2
subsets_mse <- summary(model_subset)$rss / nrow(df_train)
# Apply CV for best subset
K <-  5
folds <-  sample(1:K, nrow(df_train),replace=TRUE)
table(folds)
prediction_subsets <- function(model, new_data, id){
form <- as.formula(model$call [[2]])
mat <- model.matrix(form,new_data)
coefi <- coef(model ,id=id)
xvars <- names(coefi)
result <- mat[,xvars]%*%coefi
return(result)
}
mse_train_subset <- matrix(NA,K, 16, dimnames=list(NULL, paste(1:16)))
mse_test_subset <- matrix(NA,K, 16, dimnames=list(NULL, paste(1:16)))
for(k in 1:K){
training <- data[fold.index!=k, ]
testing <- data[fold.index==k, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = df_train, nvmax = 16)
for (i in 1:13){
pred <-  prediction_subsets(best_fit, testing, id = i)
pred_train <- prediction_subsets(best_fit, training, id=i)
mse_train_subset[k, i] <-  mean((training$ndi1_2 - pred_train)^2)
mse_test_subset[k, i] <-  mean((testing$ndi1_2 - pred)^2)
}
}
mse_train_subset <- matrix(NA,K, 16, dimnames=list(NULL, paste(1:16)))
mse_test_subset <- matrix(NA,K, 16, dimnames=list(NULL, paste(1:16)))
for(k in 1:K){
training <- df_pred_lm[fold.index!=k, ]
testing <- df_pred_lm[fold.index==k, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = df_train, nvmax = 16)
for (i in 1:13){
pred <-  prediction_subsets(best_fit, testing, id = i)
pred_train <- prediction_subsets(best_fit, training, id=i)
mse_train_subset[k, i] <-  mean((training$ndi1_2 - pred_train)^2)
mse_test_subset[k, i] <-  mean((testing$ndi1_2 - pred)^2)
}
}
mse_train_subset
mse_test_subset
mse_test_subset <- matrix(NA, K, 16, dimnames=list(NULL, paste(1:16)))
for(k in 1:K){
training <- df_pred_lm[fold.index!=k, ]
testing <- df_pred_lm[fold.index==k, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = training, nvmax = 16)
for (i in 1:13){
pred <-  prediction_subsets(best_fit, testing, id = i)
pred_train <- prediction_subsets(best_fit, training, id=i)
mse_train_subset[k, i] <-  mean((training$ndi1_2 - pred_train)^2)
mse_test_subset[k, i] <-  mean((testing$ndi1_2 - pred)^2)
}
}
for(k in 1:K){
training <- df_pred_lm[fold.index!=k, ]
testing <- df_pred_lm[fold.index==k, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = training, nvmax = 16)
for (i in 1:16){
pred <-  prediction_subsets(best_fit, testing, id = i)
pred_train <- prediction_subsets(best_fit, training, id=i)
mse_train_subset[k, i] <-  mean((training$ndi1_2 - pred_train)^2)
mse_test_subset[k, i] <-  mean((testing$ndi1_2 - pred)^2)
}
}
# Average over the folds and choose 11 predictors
mse_train_subset <- apply(mse_train_subset, 2, mean)
for(k in 1:K){
training <- df_pred_lm[fold.index!=k, ]
testing <- df_pred_lm[fold.index==k, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = df_train, nvmax = 16)
for (i in 1:16){
pred <-  prediction_subsets(best_fit, testing, id = i)
pred_train <- prediction_subsets(best_fit, training, id=i)
mse_train_subset[k, i] <-  mean((training$ndi1_2 - pred_train)^2)
mse_test_subset[k, i] <-  mean((testing$ndi1_2 - pred)^2)
}
}
training <- df_pred_lm[fold.index!=1, ]
testing <- df_pred_lm[fold.index==1, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = df_train, nvmax = 16)
training
testing
best_fit
pred <-  prediction_subsets(best_fit, testing, id = 1)
pred_train <- prediction_subsets(best_fit, training, id=1)
mean((training$ndi1_2 - pred_train)^2)
View(pred_train)
mean((testing$ndi1_2 - pred)^2)
pred
testing$ndi1_2
training$ndi1_2
best_fit
# create train (80%) and test (20%) data for best subset, ridge, lasso
shuffle_ids <- sample(c(0,1), nrow(df_pred_lm), prob = c(0.5, 0.5), replace = T)
df_train <- df_pred_lm %>%
filter(shuffle_ids == 0)
df_test <- df_pred_lm %>%
filter(shuffle_ids == 1)
for(k in 1:K){
training <- df_pred_lm[fold.index!=1, ]
testing <- df_pred_lm[fold.index==1, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = df_train, nvmax = 16)
for (i in 1:16){
pred <-  prediction_subsets(best_fit, testing, id = 1)
pred_train <- prediction_subsets(best_fit, training, id=1)
mse_train_subset[, i] <-  mean((training$ndi1_2 - pred_train)^2)
mse_test_subset[k, i] <-  mean((testing$ndi1_2 - pred)^2)
}
}
training <- df_pred_lm[fold.index!=1, ]
testing <- df_pred_lm[fold.index==1, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = df_train, nvmax = 16)
best_fit
summary(model_subset)
mdl_full <- lm(ndi1_2 ~ ., data = df_pred_lm)
summary(mdl_full)
best_summary <- summary(model_subset)
plot(best_summary$rsq)
plot(best_summary$rsq)
best_summary <- summary(model_subset)
plot(best_summary$rsq)
best_summary$rsq
plot(best_summary$rsq)
plot(best_summary$bic)
best_summary$bic
plot(model_subset, scale = "cp")
pred <-  prediction_subsets(best_fit, testing, id = 1)
pred_train <- prediction_subsets(best_fit, training, id=1)
mean((training$ndi1_2 - pred_train)^2)
training <- df_pred_lm[fold.index!=1, ]
testing <- df_pred_lm[fold.index==1, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = testing, nvmax = 16)
pred <-  prediction_subsets(best_fit, testing, id = 1)
pred
pred
prediction_subsets(best_fit, testing, id = 1)
mse_train_subset <- matrix(NA, K, 16, dimnames=list(NULL, paste(1:16)))
mse_test_subset <- matrix(NA, K, 16, dimnames=list(NULL, paste(1:16)))
for(k in 1:K){
training <- df_pred_lm[fold.index!=k, ]
testing <- df_pred_lm[fold.index==k, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = testing, nvmax = 16)
for (i in 1:16){
pred <-  prediction_subsets(best_fit, testing, id = i)
pred_train <- prediction_subsets(best_fit, training, id=i)
mse_train_subset[k, i] <-  mean((training$ndi1_2 - pred_train)^2)
mse_test_subset[k, i] <-  mean((testing$ndi1_2 - pred)^2)
}
}
for(k in 1:K){
training <- df_pred_lm[fold.index!=k, ]
testing <- df_pred_lm[fold.index==k, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = df_pred_lm, nvmax = 15)
for (i in 1:16){
pred <-  prediction_subsets(best_fit, testing, id = i)
pred_train <- prediction_subsets(best_fit, training, id=i)
mse_train_subset[k, i] <-  mean((training$ndi1_2 - pred_train)^2)
mse_test_subset[k, i] <-  mean((testing$ndi1_2 - pred)^2)
}
}
rm(list = ls())
set.seed(19950306)
library(lme4)
library(tidyverse)
library(leaps)
df_pred <- read.csv("Data/df_prediction_new_2020-03-23.csv")
# VINT01A, VINT01J, VINT01W, OSTSPOND --> to many NAs
# X, id_revalue, ndi0, hads0_tot, hads0_anx, hads0_depr --> not used
df_pred <- df_pred %>%
dplyr::select(-c(X, id_revalue, ndi0, hads0_tot, hads0_anx, hads0_depr, VINT01A, VINT01J, VINT01W,
OSTSPOND))
# create dataframe for LM (only for time = 52 weeks)
df_pred_lm <- df_pred %>%
dplyr::filter(time_fct == 52) %>%
dplyr::select(-c(id, time_fct)) # dont need these variables
# create train (80%) and test (20%) data for best subset, ridge, lasso
shuffle_ids <- sample(c(0,1), nrow(df_pred_lm), prob = c(0.5, 0.5), replace = T)
df_train <- df_pred_lm %>%
filter(shuffle_ids == 0)
df_test <- df_pred_lm %>%
filter(shuffle_ids == 1)
K <- 5
index <- rep(1:K, floor(nrow(df_pred_lm)/K)+1)[1:nrow(df_pred_lm)]
fold.index <- sample(index)
prediction_subsets <- function(model, new_data, id){
form <- as.formula(model$call [[2]])
mat <- model.matrix(form,new_data)
coefi <- coef(model ,id=id)
xvars <- names(coefi)
result <- mat[,xvars]%*%coefi
return(result)
}
mse_train_subset <- matrix(NA, K, 16, dimnames=list(NULL, paste(1:16)))
mse_test_subset <- matrix(NA, K, 16, dimnames=list(NULL, paste(1:16)))
for(k in 1:K){
training <- df_pred_lm[fold.index!=k, ]
testing <- df_pred_lm[fold.index==k, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = df_pred_lm, nvmax = 15)
for (i in 1:16){
pred <-  prediction_subsets(best_fit, testing, id = i)
pred_train <- prediction_subsets(best_fit, training, id=i)
mse_train_subset[k, i] <-  mean((training$ndi1_2 - pred_train)^2)
mse_test_subset[k, i] <-  mean((testing$ndi1_2 - pred)^2)
}
}
for(k in 1:K){
training <- df_pred_lm[fold.index!=k, ]
testing <- df_pred_lm[fold.index==k, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = training, nvmax = 15)
for (i in 1:16){
pred <-  prediction_subsets(best_fit, testing, id = i)
pred_train <- prediction_subsets(best_fit, training, id=i)
mse_train_subset[k, i] <-  mean((training$ndi1_2 - pred_train)^2)
mse_test_subset[k, i] <-  mean((testing$ndi1_2 - pred)^2)
}
}
cv.errors <- matrix(NA, K, 16, dimnames=list(NULL, paste(1:16)))
cv.errors
for(j in 1:K){
# Fit the model with each subset of predictors on the training part of the fold
best.fit=regsubsets(ndi1_2 ~.,data=df_pred_lm[folds!=j,], nvmax=15)
# For each subset
for(i in 1:15){
# Predict on the hold out part of the fold for that subset
pred=predict(best.fit, df_pred_lm[folds==j,],id=i)
# Get the mean squared error for the model trained on the fold with the subset
cv.errors[j,i]=mean((df_pred_lm$Salary[folds==j]-pred)^2)
}
}
folds <-  sample(1:K, nrow(df_pred_lm),replace=TRUE)
for(j in 1:K){
# Fit the model with each subset of predictors on the training part of the fold
best.fit=regsubsets(ndi1_2 ~.,data=df_pred_lm[folds!=j,], nvmax=15)
# For each subset
for(i in 1:15){
# Predict on the hold out part of the fold for that subset
pred=predict(best.fit, df_pred_lm[folds==j,],id=i)
# Get the mean squared error for the model trained on the fold with the subset
cv.errors[j,i]=mean((df_pred_lm$Salary[folds==j]-pred)^2)
}
}
cv.errors
cv.errors <- matrix(NA, K, 16, dimnames=list(NULL, paste(1:16)))
folds <-  sample(1:K, nrow(df_pred_lm),replace=TRUE)
for(j in 1:K){
# Fit the model with each subset of predictors on the training part of the fold
best.fit=regsubsets(ndi1_2 ~.,data=df_pred_lm[folds!=j,], nvmax=15)
# For each subset
for(i in 1:15){
# Predict on the hold out part of the fold for that subset
pred=predict(best.fit, df_pred_lm[folds==j,],id=i)
# Get the mean squared error for the model trained on the fold with the subset
cv.errors[j,i]=mean((df_pred_lm$ndi1_2[folds==j]-pred)^2)
}
}
cv.errors
mean((df_pred_lm$ndi1_2[folds==j]-pred)^2)
folds
# Fit the model with each subset of predictors on the training part of the fold
best.fit=regsubsets(ndi1_2 ~.,data=df_pred_lm[folds!=1,], nvmax=15)
# Predict on the hold out part of the fold for that subset
pred=predict(best.fit, df_pred_lm[folds==1,],id=1)
# Predict on the hold out part of the fold for that subset
pred=prediction_subsets(best.fit, df_pred_lm[folds==1,],id=1)
mean((df_pred_lm$ndi1_2[folds==1]-pred)^2)
df_pred_lm$ndi1_2[folds==1]
pred
df_pred_lm[folds==1,]
table(folds)
best.fit
pred=prediction_subsets(best.fit, df_pred_lm[folds==1,],id=1)
df_pred_lm$ndi1_2[folds==1]
length(df_pred_lm$ndi1_2[folds==1])
# Predict on the hold out part of the fold for that subset
pred=prediction_subsets(best.fit, df_pred_lm[folds==1,],id=1)
df_pred_lm$ndi1_2[folds==1]-pred
View(mse_train_subset)
View(pred)
df_pred_lm$ndi1_2[folds==1]
y <- df_pred_lm$ndi1_2[folds==1]
length(y)
length(pred)
table(folds)
folds <-  sample(1:K, nrow(df_pred_lm),replace=TRUE)
table(folds)
# Fit the model with each subset of predictors on the training part of the fold
best.fit=regsubsets(ndi1_2 ~.,data=df_pred_lm[folds!=1,], nvmax=15)
# Predict on the hold out part of the fold for that subset
pred=prediction_subsets(best.fit, df_pred_lm[folds==1,],id=1)
length(pred)
mse_train_subset <- matrix(NA, K, 16, dimnames=list(NULL, paste(1:16)))
mse_test_subset <- matrix(NA, K, 16, dimnames=list(NULL, paste(1:16)))
for(k in 1:K){
training <- df_pred_lm[fold.index!=k, ]
testing <- df_pred_lm[fold.index==k, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = training, nvmax = 15)
for (i in 1:15){
pred <-  prediction_subsets(best_fit, testing, id = i)
pred_train <- prediction_subsets(best_fit, training, id=i)
mse_train_subset[k, i] <-  mean((training$ndi1_2 - pred_train)^2)
mse_test_subset[k, i] <-  mean((testing$ndi1_2 - pred)^2)
}
}
09/5
90/5
# remove 3 subjects to make number even (90/5=18)
df_pred_lm <- df_pred_lm[-c(91:93),]
K <- 5
index <- rep(1:K, floor(nrow(df_pred_lm)/K)+1)[1:nrow(df_pred_lm)]
fold.index <- sample(index)
fold.index
table(fold.index)
prediction_subsets <- function(model, new_data, id){
form <- as.formula(model$call [[2]])
mat <- model.matrix(form,new_data)
coefi <- coef(model ,id=id)
xvars <- names(coefi)
result <- mat[,xvars]%*%coefi
return(result)
}
mse_train_subset <- matrix(NA, K, 16, dimnames=list(NULL, paste(1:16)))
mse_test_subset <- matrix(NA, K, 16, dimnames=list(NULL, paste(1:16)))
for(k in 1:K){
training <- df_pred_lm[fold.index!=k, ]
testing <- df_pred_lm[fold.index==k, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = training, nvmax = 15)
for (i in 1:16){
pred <-  prediction_subsets(best_fit, testing, id = i)
pred_train <- prediction_subsets(best_fit, training, id=i)
mse_train_subset[k, i] <-  mean((training$ndi1_2 - pred_train)^2)
mse_test_subset[k, i] <-  mean((testing$ndi1_2 - pred)^2)
}
}
cv.errors <- matrix(NA, K, 16, dimnames=list(NULL, paste(1:16)))
folds <-  sample(1:K, nrow(df_pred_lm),replace=TRUE)
table(folds)
fold.index
folds <- fold.index
for(j in 1:K){
# Fit the model with each subset of predictors on the training part of the fold
best.fit=regsubsets(ndi1_2 ~.,data=df_pred_lm[folds!=1,], nvmax=15)
# For each subset
for(i in 1:15){
# Predict on the hold out part of the fold for that subset
pred=prediction_subsets(best.fit, df_pred_lm[folds==1,],id=1)
# Get the mean squared error for the model trained on the fold with the subset
cv.errors[j,i]=mean((df_pred_lm$ndi1_2[folds==1]-pred)^2)
}
}
for(j in 1:K){
# Fit the model with each subset of predictors on the training part of the fold
best.fit=regsubsets(ndi1_2 ~.,data=df_pred_lm[folds!=j,], nvmax=15)
# For each subset
for(i in 1:16){
# Predict on the hold out part of the fold for that subset
pred=prediction_subsets(best.fit, df_pred_lm[folds==j,],id=i)
# Get the mean squared error for the model trained on the fold with the subset
cv.errors[j,i]=mean((df_pred_lm$ndi1_2[folds==j]-pred)^2)
}
}
for(k in 1:K){
training <- df_pred_lm[fold.index!=k, ]
testing <- df_pred_lm[fold.index==k, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = training, nvmax = 15)
for (i in 1:16){
pred <-  prediction_subsets(best_fit, testing, id = i)
pred_train <- prediction_subsets(best_fit, training, id=i)
mse_train_subset[k, i] <-  mean((training$ndi1_2 - pred_train)^2)
mse_test_subset[k, i] <-  mean((testing$ndi1_2 - pred)^2)
}
}
training <- df_pred_lm[fold.index!=1, ]
testing <- df_pred_lm[fold.index==1, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = training, nvmax = 15)
pred <-  prediction_subsets(best_fit, testing, id = i)
pred <-  prediction_subsets(best_fit, testing, id = 1)
pred
View(pred)
length(pred)
pred <-  prediction_subsets(best_fit, testing, id = 18)
pred <-  prediction_subsets(best_fit, testing, id = 2)
pred_train <- prediction_subsets(best_fit, training, id=2)
16=54
16+54
View(pred_train)
prediction_subsets(best_fit, testing, id = 2)
best_fit <- regsubsets(ndi1_2 ~ ., data = training, nvmax = 16)
best_fit
prediction_subsets(best_fit, testing, id = 2)
mse_train_subset <- matrix(NA, K, 18, dimnames=list(NULL, paste(1:16)))
mse_test_subset <- matrix(NA, K, 18, dimnames=list(NULL, paste(1:16)))
mse_train_subset <- matrix(NA, K, 18, dimnames=list(NULL, paste(1:18)))
mse_test_subset <- matrix(NA, K, 18, dimnames=list(NULL, paste(1:18)))
for(k in 1:K){
training <- df_pred_lm[fold.index!=1, ]
testing <- df_pred_lm[fold.index==1, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = training, nvmax = 16)
for (i in 1:18){
pred <-  prediction_subsets(best_fit, testing, id = i)
pred_train <- prediction_subsets(best_fit, training, id=i)
mse_train_subset[k, i] <-  mean((training$ndi1_2 - pred_train)^2)
mse_test_subset[k, i] <-  mean((testing$ndi1_2 - pred)^2)
}
}
training <- df_pred_lm[fold.index!=k, ]
testing <- df_pred_lm[fold.index==k, ]
for(k in 1:K){
training <- df_pred_lm[fold.index!=k, ]
testing <- df_pred_lm[fold.index==k, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = training, nvmax = 16)
for (i in 1:18){
pred <-  prediction_subsets(best_fit, testing, id = i)
pred_train <- prediction_subsets(best_fit, training, id=i)
mse_train_subset[k, i] <-  mean((training$ndi1_2 - pred_train)^2)
mse_test_subset[k, i] <-  mean((testing$ndi1_2 - pred)^2)
}
}
rm(list = ls())
set.seed(19950306)
library(lme4)
library(tidyverse)
library(leaps)
df_pred <- read.csv("Data/df_prediction_new_2020-03-23.csv")
# VINT01A, VINT01J, VINT01W, OSTSPOND --> to many NAs
# X, id_revalue, ndi0, hads0_tot, hads0_anx, hads0_depr --> not used
df_pred <- df_pred %>%
dplyr::select(-c(X, id_revalue, ndi0, hads0_tot, hads0_anx, hads0_depr, VINT01A, VINT01J, VINT01W,
OSTSPOND))
# create dataframe for LM (only for time = 52 weeks)
df_pred_lm <- df_pred %>%
dplyr::filter(time_fct == 52) %>%
dplyr::select(-c(id, time_fct)) # dont need these variables
# create train (80%) and test (20%) data for best subset, ridge, lasso
shuffle_ids <- sample(c(0,1), nrow(df_pred_lm), prob = c(0.5, 0.5), replace = T)
rm(list = ls())
set.seed(19950306)
library(lme4)
library(tidyverse)
library(leaps)
df_pred <- read.csv("Data/df_prediction_new_2020-03-23.csv")
# VINT01A, VINT01J, VINT01W, OSTSPOND --> to many NAs
# X, id_revalue, ndi0, hads0_tot, hads0_anx, hads0_depr --> not used
df_pred <- df_pred %>%
dplyr::select(-c(X, id_revalue, ndi0, hads0_tot, hads0_anx, hads0_depr, VINT01A, VINT01J, VINT01W,
OSTSPOND))
# create dataframe for LM (only for time = 52 weeks)
df_pred_lm <- df_pred %>%
dplyr::filter(time_fct == 52) %>%
dplyr::select(-c(id, time_fct)) # dont need these variables
K <- 5
index <- rep(1:K, floor(nrow(df_pred_lm)/K)+1)[1:nrow(df_pred_lm)]
fold.index <- sample(index)
table(fold.index)
# Apply CV for best subset
prediction_subsets <- function(model, new_data, id){
form <- as.formula(model$call [[2]])
mat <- model.matrix(form,new_data)
coefi <- coef(model ,id=id)
xvars <- names(coefi)
result <- mat[,xvars]%*%coefi
return(result)
}
mse_train_subset <- matrix(NA, K, 16, dimnames=list(NULL, paste(1:16)))
mse_test_subset <- matrix(NA, K, 16, dimnames=list(NULL, paste(1:16)))
for(k in 1:K){
training <- df_pred_lm[fold.index!=k, ]
testing <- df_pred_lm[fold.index==k, ]
best_fit <- regsubsets(ndi1_2 ~ ., data = training, nvmax = 16)
for (i in 1:16){
pred <-  prediction_subsets(best_fit, testing, id = i)
pred_train <- prediction_subsets(best_fit, training, id=i)
mse_train_subset[k, i] <-  mean((training$ndi1_2 - pred_train)^2)
mse_test_subset[k, i] <-  mean((testing$ndi1_2 - pred)^2)
}
}
# Average over the folds and choose 11 predictors
mse_train_subset <- apply(mse_train_subset, 2, mean)
mse_test_subset <- apply(mse_test_subset, 2, mean)
mse_train_subset
mse_test_subset
which.min(mse_test_subset)

weights = rep_len(1, 17), lambda = 2, standardize = T)
mld_lmm$aic
summary(mld_lmm)
mld_lmm <- lmmlasso(x=xmat, y=ymat, z = ids, grp = ids,
weights = rep_len(1, 17), lambda = 0.5, standardize = T)
mld_lmm$aic
summary(mld_lmm)
plot(mld_lmm)
mld_lmm$lambda
mld_lmm$random
plot(mld_lmm$random)
mld_lmm$fitted.values
print(mld_lmm)
mld_lmm$fixef
print(mld_lmm)
summary(cv.lmmlasso)
cv.lmmlasso <- lmmen::cv.lmmlasso(dat = Test_Matrix, lambda = seq(0,10,100))
plot(cv.lmmlasso$BIC_path)
summary(cv.lmmlasso)
cv.lmmlasso
seq(0,10,100)
seq(0,10)
.01
cv.lmmlasso <- lmmen::cv.lmmlasso(dat = Test_Matrix, lambda = seq(0,10,0.01))
cv.lmmlasso
plot(cv.lmmlasso$BIC_path)
summary(cv.lmmlasso)
grid <- seq(0,10,0.01)
t
plot(cv.lmmlasso)
which.min(cv.lmmlasso$BIC_path)
grid[136]
optimal_lambda <- grid[which.min(cv.lmmlasso$BIC_path)]
length(cv.lmmlasso$BIC_path)
cv.lmmlasso$BIC_path
mld_lmm <- lmmlasso(x=xmat, y=ymat, z = ids, grp = ids,
weights = rep_len(1, 17), lambda = optimal_lambda, standardize = T)
summary(mld_lmm)
print(mld_lmm)
summary(mld_lmm)
mld_lmm <- lmmlasso(x=xmat, y=ymat, z = ids, grp = ids,
weights = NA, lambda = optimal_lambda, standardize = T)
rep_len(1, 17)
fold(df_pred, k = K, id_col = "id_revalue") %>%
print(n=Inf)
# cross validation
K <- 5
df_pred <- fold(df_pred, k = K, id_col = "id_revalue") %>%
print(n=Inf)
# cross validation
library(groupdata2)
K <- 5
df_pred <- fold(df_pred, k = K, id_col = "id_revalue") %>%
print(n=Inf)
mse_lasso_CV <- numeric(K)
for(j in 1:K){
x_train <- model.matrix(ndi1_2~.-id_revalue -int,
data= df_pred[fold.index != j,])[,-1]
y_train <- df_pred_lm[fold.index != j,]$ndi1_2
x_test <- model.matrix(ndi1_2~-id_revalue -int,
data=df_pred[fold.index == j, ])[,-1]
y_test <- df_pred[fold.index == j, ]$ndi1_2
lasso.mod <-  lmmlasso(x=xmat, y=ymat, z = ids, grp = ids,
weights = rep_len(1, 17), lambda = optimal_lambda, standardize = T)
pred.lasso <- predict(lasso.mod,s=optimal_lambda, newx=x_test)
mse_lasso_CV[j] <-mean((pred.lasso -y_test)^2)
}
View(df_pred)
fold.index <- fold(df_pred, k = K, id_col = "id_revalue") %>%
print(n=Inf)
fold.index
x_train <- model.matrix(ndi1_2~.-id_revalue -int,
data= df_pred[,df_pred$.fold != j])[,-c(1:2,19,20)]
x_train <- model.matrix(ndi1_2~.,
data= df_pred[,df_pred$.fold != j])[,-c(1:2,19,20)]
df_pred2 <- df_pred %>% select(-.folds)
df_pred2 <- df_pred %>% select(-c(.folds, id_revalue))
df_pred <- read.csv("Data/df_prediction_new_2020-03-23.csv")
# create dataframe for LM (only for time = 52 weeks)
df_pred_lm <- df_pred %>%
dplyr::filter(time_fct == 52) %>%
dplyr::select(-c(id, time_fct)) %>% # dont need these variables
na.omit()
# VINT01A, VINT01J, VINT01W, OSTSPOND --> to many NAs
# X, id_revalue, ndi0, hads0_tot, hads0_anx, hads0_depr --> not used
df_pred <- df_pred %>%
dplyr::select(-c(X, id, ndi0, hads0_tot, hads0_anx, hads0_depr, VINT01A, VINT01J, VINT01W,
OSTSPOND, DHindexlevelBaseline)) %>%
mutate(ndi1_2 = as.numeric(ndi1_2)) %>%
na.omit(.) # remove NAs
df_pred <- read.csv("Data/df_prediction_new_2020-03-23.csv")
# create dataframe for LM (only for time = 52 weeks)
df_pred_lm <- df_pred %>%
dplyr::filter(time_fct == 52) %>%
dplyr::select(-c(id, time_fct)) %>% # dont need these variables
na.omit()
# VINT01A, VINT01J, VINT01W, OSTSPOND --> to many NAs
# X, id_revalue, ndi0, hads0_tot, hads0_anx, hads0_depr --> not used
df_pred <- df_pred %>%
dplyr::select(-c(X, id, ndi0, hads0_tot, hads0_anx, hads0_depr, VINT01A, VINT01J, VINT01W,
OSTSPOND)) %>%
mutate(ndi1_2 = as.numeric(ndi1_2)) %>%
na.omit(.) # remove NAs
df_pred$int <- 1
xmat <- as.matrix(df_pred[, c(20, 3:19)])
ymat <- as.matrix(df_pred[,2])
ids <- as.matrix(df_pred[,1])
# test_matrix = y+X+Z
Test_Matrix <- cbind(ymat, xmat, ids)
colnames(Test_Matrix) <- c("y", sprintf("X%s",1:17), "Z")
colnames(Test_Matrix) <- c("y", sprintf("X%s",1:18), "Z")
rownames(Test_Matrix) <- df_pred$id_revalue
# find optimal lambda
grid <- seq(0,10,0.01)
cv.lmmlasso <- lmmen::cv.lmmlasso(dat = Test_Matrix, lambda = grid)
xmat <- as.matrix(df_pred[, c(3:19)])
xmat_int <- as.matrix(df_pred[, c(20, 3:19)])
ymat <- as.matrix(df_pred[,2])
ids <- as.matrix(df_pred[,1])
# test_matrix = y+X+Z
Test_Matrix <- cbind(ymat, xmat, ids)
colnames(Test_Matrix) <- c("y", sprintf("X%s",1:18), "Z")
rownames(Test_Matrix) <- df_pred$id_revalue
# find optimal lambda
grid <- seq(0,10,0.01)
xmat <- as.matrix(df_pred[, c(3:19)])
# find optimal lambda
grid <- seq(0,10,0.01)
cv.lmmlasso <- lmmen::cv.lmmlasso(dat = Test_Matrix, lambda = grid)
xmat <- as.matrix(df_pred[, c(3:19)])
xmat_int <- as.matrix(df_pred[, c(20, 3:19)])
ymat <- as.matrix(df_pred[,2])
ids <- as.matrix(df_pred[,1])
# test_matrix = y+X+Z
Test_Matrix <- cbind(ymat, xmat, ids)
colnames(Test_Matrix) <- c("y", sprintf("X%s",1:18), "Z")
rownames(Test_Matrix) <- df_pred$id_revalue
colnames(Test_Matrix) <- c("y", sprintf("X%s",1:17), "Z")
rownames(Test_Matrix) <- df_pred$id_revalue
# find optimal lambda
grid <- seq(0,10,0.01)
cv.lmmlasso <- lmmen::cv.lmmlasso(dat = Test_Matrix, lambda = grid)
cv.lmmlasso
plot(cv.lmmlasso$BIC_path)
plot(cv.lmmlasso$BIC_path)
plot(cv.lmmlasso$BIC_path)
optimal_lambda <- grid[which.min(cv.lmmlasso$BIC_path)]
mld_lmm <- lmmlasso(x=xmat, y=ymat, z = ids, grp = ids,
weights = rep_len(1, 17), lambda = optimal_lambda, standardize = T)
mld_lmm <- lmmlasso(x=xmat_int, y=ymat, z = ids, grp = ids,
weights = rep_len(1, 17), lambda = optimal_lambda, standardize = T)
mld_lmm <- lmmlasso(x=xmat_int, y=ymat, z = ids, grp = ids,
weights = rep_len(1, 18), lambda = optimal_lambda, standardize = T)
summary(mld_lmm)
# cross validation
library(groupdata2)
df_pred2 <- df_pred %>% select(-c(id_revalue))
K <- 5
df_pred <- fold(df_pred, k = K, id_col = "id_revalue") %>%
print(n=Inf)
mse_lasso_CV <- numeric(K)
for(j in 1:K){
x_train <- model.matrix(ndi1_2~.,
data= df_pred2[df_pred$.fold != j])[,-1]
y_train <- df_pred2[df_pred$fold.index != j,]$ndi1_2
x_test <- model.matrix(ndi1_2~.,
data=df_pred2[df_pred$fold.index == j, ])[,-1]
y_test <- df_pred2[df_pred$fold.index == j, ]$ndi1_2
lasso.mod <-  lmmlasso(x=xmat_int, y=ymat, z = ids, grp = ids,
weights = rep_len(1, 17), lambda = optimal_lambda, standardize = T)
pred.lasso <- predict(lasso.mod,s=optimal_lambda, newx=x_test)
mse_lasso_CV[j] <-mean((pred.lasso - y_test)^2)
}
mse_lasso_CV <- numeric(K)
for(j in 1:K){
x_train <- model.matrix(ndi1_2~.,
data= df_pred2[df_pred$.folds != j])[,-1]
y_train <- df_pred2[df_pred$fold.index != j,]$ndi1_2
x_test <- model.matrix(ndi1_2~.,
data=df_pred2[df_pred$.folds == j, ])[,-1]
y_test <- df_pred2[df_pred$.folds == j, ]$ndi1_2
lasso.mod <-  lmmlasso(x=xmat_int, y=ymat, z = ids, grp = ids,
weights = rep_len(1, 17), lambda = optimal_lambda, standardize = T)
pred.lasso <- predict(lasso.mod,s=optimal_lambda, newx=x_test)
mse_lasso_CV[j] <-mean((pred.lasso - y_test)^2)
}
mean(mse_lasso_CV)#163.811
mse_lasso_CV
x_train <- model.matrix(ndi1_2~.,
data= df_pred2[df_pred$.folds != j])[,-1]
x_train <- model.matrix(ndi1_2~.,
data= df_pred2[df_pred$.folds != 1])[,-1]
df_pred2[df_pred$.folds != 1]
x_train <- model.matrix(ndi1_2~.,
data= df_pred2[,-1])[df_pred$.folds != 1]
x_train <- model.matrix(ndi1_2~.,
data= df_pred2)[df_pred$.folds != 1]
x_train <- xtrain[,1]
x_train <- model.matrix(ndi1_2~.,
data= df_pred2)[df_pred$.folds != 1]
x_train <- xtrain[,1]
x_train <- x_train[,1]
library(lme4)
library(tidyverse)
library(leaps)
library(glmnet)
library(lmmlasso)
library(lmmen)
optimal_lambda <- grid[which.min(cv.lmmlasso$BIC_path)]
cv.lmmlasso
plot(cv.lmmlasso$BIC_path)
optimal_lambda <- grid[which.min(cv.lmmlasso$BIC_path)]
mld_lmm <- lmmlasso(x=xmat_int, y=ymat, z = ids, grp = ids,
weights = rep_len(1, 18), lambda = optimal_lambda, standardize = T)
summary(mld_lmm)
View(df_pred)
View(df_pred)
# cross validation
library(groupdata2)
df_pred2 <- df_pred %>% select(-c(id_revalue))
K <- 5
df_pred <- fold(df_pred, k = K, id_col = "id_revalue") %>%
print(n=Inf)
grid[which.min(cv.lmmlasso$BIC_path)]
mse_lasso_CV <- numeric(K)
for(j in 1:K){
x_train <- model.matrix(ndi1_2~.,
data= df_pred2)[df_pred$.folds != 1]
x_train <- x_train[,1]
y_train <- df_pred2[df_pred$fold.index != j,]$ndi1_2
x_test <- model.matrix(ndi1_2~.,
data=df_pred2[df_pred$.folds == j, ])[,-1]
y_test <- df_pred2[df_pred$.folds == j, ]$ndi1_2
lasso.mod <-  lmmlasso(x=xmat_int, y=ymat, z = ids, grp = ids,
weights = rep_len(1, 17), lambda = optimal_lambda, standardize = T)
pred.lasso <- predict(lasso.mod,s=optimal_lambda, newx=x_test)
mse_lasso_CV[j] <-mean((pred.lasso - y_test)^2)
}
mse_lasso_CV <- numeric(K)
for(j in 1:K){
x_train <- model.matrix(ndi1_2~.,
data= df_pred2)[df_pred$.folds != j]
x_train <- x_train[,1]
y_train <- df_pred2[df_pred$fold.index != j,]$ndi1_2
x_test <- model.matrix(ndi1_2~.,
data=df_pred2[df_pred$.folds == j, ])[,-1]
y_test <- df_pred2[df_pred$.folds == j, ]$ndi1_2
lasso.mod <-  lmmlasso(x=xmat_int, y=ymat, z = ids, grp = ids,
weights = rep_len(1, 17), lambda = optimal_lambda, standardize = T)
pred.lasso <- predict(lasso.mod,s=optimal_lambda, newx=x_test)
mse_lasso_CV[j] <-mean((pred.lasso - y_test)^2)
}
mse_lasso_CV
model.matrix(ndi1_2~.,
data= df_pred2)[df_pred$.folds != 1]
x_train <- model.matrix(ndi1_2~.,
data= df_pred2)[df_pred$.folds != 1]
str(x_train)
y_train <- df_pred2[df_pred$fold.index != 1,]$ndi1_2
x_train <- model.matrix(ndi1_2~.,
data= df_pred2)#[df_pred$.folds != 1]
x_train <- model.matrix(ndi1_2~.,
data= df_pred2[df_pred$.folds != 1])
df_pred$.folds != 1
x_train <- model.matrix(ndi1_2~ -id_revalue,
data= df_pred[df_pred$.folds != 1])
x_train <- model.matrix(ndi1_2~ -id_revalue,
data= df_pred[,df_pred$.folds != 1])
View(x_train)
View(df_pred)
x_train <- model.matrix(ndi1_2~ .,
data= df_pred2)
View(x_train)
View(df_pred2)
df_pred2 <- df_pred %>% select(-c(id_revalue, .folds))
View(df_pred2)
df_pred2 <- df_pred %>% select(-c(id_revalue, .folds, int))
View(df_pred)
View(df_pred2)
View(df_pred)
df_pred2 <- df_pred %>% select(-c(id_revalue, .folds, int))
df_pred <- read.csv("Data/df_prediction_new_2020-03-23.csv")
# VINT01A, VINT01J, VINT01W, OSTSPOND --> to many NAs
# X, id_revalue, ndi0, hads0_tot, hads0_anx, hads0_depr --> not used
df_pred <- df_pred %>%
dplyr::select(-c(X, id, ndi0, hads0_tot, hads0_anx, hads0_depr, VINT01A, VINT01J, VINT01W,
OSTSPOND)) %>%
mutate(ndi1_2 = as.numeric(ndi1_2)) %>%
na.omit(.) # remove NAs
View(df_pred)
df_pred$int <- 1
df_pred2 <- df_pred %>% select(-c(id_revalue, int))
View(df_pred2)
x_train <- model.matrix(ndi1_2~ .,
data= df_pred2)
x_train <- model.matrix(ndi1_2~ .,
data= df_pred2)[df_pred$.fold == 1]
x_train <- model.matrix(ndi1_2~ .,
data= df_pred2)[df_pred$.folds == 1]
x_train <- model.matrix(ndi1_2~ .,
data= df_pred2[df_pred$.folds == 1])
df_pred <- fold(df_pred, k = K, id_col = "id_revalue") %>%
print(n=Inf)
View(df_pred)
lasso.mod <-  lmmlasso(x=xmat_int, y=ymat, z = ids, grp = ids,
weights = rep_len(1, 17), lambda = optimal_lambda, standardize = T)
x_train <- model.matrix(ndi1_2~ .,
data= df_pred2[df_pred$.folds == 1])
df_pre
df_pred[df_pred$ndi1_2 > 20, ]
x_train <- model.matrix(ndi1_2~ .,
data= df_pred2[df_pred$.folds == 1,])
mse_lasso_CV <- numeric(K)
for(j in 1:K){
x_train <- model.matrix(ndi1_2~ .,
data= df_pred2[df_pred$.folds == j,])
x_train <- x_train[,1]
y_train <- df_pred2[df_pred$fold.index != 1,]$ndi1_2
x_test <- model.matrix(ndi1_2~.,
data=df_pred2[df_pred$.folds == j, ])[,-1]
y_test <- df_pred2[df_pred$.folds == j, ]$ndi1_2
lasso.mod <-  lmmlasso(x=xmat_int, y=ymat, z = ids, grp = ids,
weights = rep_len(1, 17), lambda = optimal_lambda, standardize = T)
pred.lasso <- predict(lasso.mod,s=optimal_lambda, newx=x_test)
mse_lasso_CV[j] <-mean((pred.lasso - y_test)^2)
}
mse_lasso_CV <- numeric(K)
for(j in 1:K){
x_train <- model.matrix(ndi1_2~ .,
data= df_pred2[df_pred$.folds == j,])
x_train <- x_train[,1]
y_train <- df_pred2[df_pred$fold.index != 1,]$ndi1_2
x_test <- model.matrix(ndi1_2~.,
data=df_pred2[df_pred$.folds == j, ])[,-1]
y_test <- df_pred2[df_pred$.folds == j, ]$ndi1_2
lasso.mod <-  lmmlasso(x=xmat_int, y=ymat, z = ids, grp = ids,
weights = rep_len(1, 18), lambda = optimal_lambda, standardize = T)
pred.lasso <- predict(lasso.mod,s=optimal_lambda, newx=x_test)
mse_lasso_CV[j] <-mean((pred.lasso - y_test)^2)
}
lasso.mod
cv.lmmlasso$fit.opt
x_train <- model.matrix(ndi1_2~.,data=df_train)[,-1]
# create dataframe for LM (only for time = 52 weeks)
df_pred_lm <- df_pred %>%
dplyr::filter(time_fct == 52) %>%
dplyr::select(-c(id, time_fct)) %>% # dont need these variables
na.omit()
df_pred <- read.csv("Data/df_prediction_new_2020-03-23.csv")
# create dataframe for LM (only for time = 52 weeks)
df_pred_lm <- df_pred %>%
dplyr::filter(time_fct == 52) %>%
dplyr::select(-c(id, time_fct)) %>% # dont need these variables
na.omit()
# VINT01A, VINT01J, VINT01W, OSTSPOND --> to many NAs
# X, id_revalue, ndi0, hads0_tot, hads0_anx, hads0_depr --> not used
df_pred <- df_pred %>%
dplyr::select(-c(X, id, ndi0, hads0_tot, hads0_anx, hads0_depr, VINT01A, VINT01J, VINT01W,
OSTSPOND)) %>%
mutate(ndi1_2 = as.numeric(ndi1_2)) %>%
na.omit(.) # remove NAs
# create train (80%) and test (20%) data for best subset, ridge, lasso
shuffle_ids <- sample(c(0,1), nrow(df_pred_lm), prob = c(0.5, 0.5), replace = T)
df_train <- df_pred_lm %>% filter(shuffle_ids == 0) %>% na.omit()
df_test <- df_pred_lm %>% filter(shuffle_ids == 1) %>% na.omit()
x_train <- model.matrix(ndi1_2~.,data=df_train)[,-1]
y_train <- df_train$ndi1_2
x_test <- model.matrix(ndi1_2~.,data=df_test)[,-1]
y_test <- df_test$ndi1_2
grid <- 10^seq(10,-2, length =100)
#implement the model and find the right lambda
lasso_MSE <- matrix(data=numeric(5*100),nrow=5,ncol=100)
lasso.mod <- glmnet(x_train, y_train, alpha=1, lambda=grid, standardize=TRUE)
lasso.mod
lasso.mod <- glmnet(x_train, y_train, alpha=1, lambda=grid, standardize=TRUE)
x_train <- model.matrix(ndi1_2~.,data=df_train)[,-1]
y_train <- df_train$ndi1_2
x_test <- model.matrix(ndi1_2~.,data=df_test)[,-1]
y_test <- df_test$ndi1_2
grid <- 10^seq(10,-2, length =100)
#implement the model and find the right lambda
lasso_MSE <- matrix(data=numeric(5*100),nrow=5,ncol=100)
lasso.mod <- glmnet(x_train, y_train, alpha=1, lambda=grid, standardize=TRUE)
View(x_test)
x_train <- model.matrix(ndi1_2~.,data=df_train)[,-1]
View(x_train)
# create train (80%) and test (20%) data for best subset, ridge, lasso
shuffle_ids <- sample(c(0,1), nrow(df_pred_lm), prob = c(0.5, 0.5), replace = T)
shuffle_ids
# create dataframe for LM (only for time = 52 weeks)
df_pred_lm <- df_pred %>%
dplyr::filter(time_fct == 52) %>%
dplyr::select(-c(id, time_fct)) %>% # dont need these variables
na.omit()
df_pred <- read.csv("Data/df_prediction_new_2020-03-23.csv")
# create dataframe for LM (only for time = 52 weeks)
df_pred_lm <- df_pred %>%
dplyr::filter(time_fct == 52) %>%
dplyr::select(-c(id, time_fct)) %>% # dont need these variables
na.omit()
# VINT01A, VINT01J, VINT01W, OSTSPOND --> to many NAs
# X, id_revalue, ndi0, hads0_tot, hads0_anx, hads0_depr --> not used
df_pred <- df_pred %>%
dplyr::select(-c(X, id, ndi0, hads0_tot, hads0_anx, hads0_depr, VINT01A, VINT01J, VINT01W,
OSTSPOND)) %>%
mutate(ndi1_2 = as.numeric(ndi1_2)) %>%
na.omit(.) # remove NAs
df_pred <- read.csv("Data/df_prediction_new_2020-03-23.csv")
# create dataframe for LM (only for time = 52 weeks)
df_pred_lm <- df_pred %>%
dplyr::filter(time_fct == 52) %>%
dplyr::select(-c(X, id, time_fct)) %>% # dont need these variables
na.omit()
# create dataframe for LM (only for time = 52 weeks)
df_pred_lm <- df_pred %>%
dplyr::filter(time_fct == 52) %>%
dplyr::select(-c(X, id, time_fct)) %>% # dont need these variables
na.omit(.)
# create dataframe for LM (only for time = 52 weeks)
df_pred_lm <- df_pred %>%
dplyr::filter(time_fct == 52) %>%
dplyr::select(-c(X, id, time_fct)) #%>% # dont need these variables
View(df_pred_lm)
View(df_pred_lm)
# create dataframe for LM (only for time = 52 weeks)
df_pred_lm <- df_pred %>%
dplyr::filter(time_fct == 52) %>%
dplyr::select(-c(X, id, time_fct, id_revalue)) #%>% # dont need these variables
na.omit(df_pred_lm)
df_pred <- read.csv("Data/df_prediction_new_2020-03-23.csv")
# create dataframe for LM (only for time = 52 weeks)
df_pred_lm <- df_pred %>%
dplyr::filter(time_fct == 52) %>%
dplyr::select(-c(X, id, time_fct, id_revalue)) #%>% # dont need these variables
# VINT01A, VINT01J, VINT01W, OSTSPOND --> to many NAs
# X, id_revalue, ndi0, hads0_tot, hads0_anx, hads0_depr --> not used
df_pred <- df_pred %>%
dplyr::select(-c(X, id, ndi0, hads0_tot, hads0_anx, hads0_depr, VINT01A, VINT01J, VINT01W,
OSTSPOND)) %>%
mutate(ndi1_2 = as.numeric(ndi1_2)) %>%
na.omit(.) # remove NAs
df_pred <- read.csv("Data/df_prediction_new_2020-03-23.csv")
# VINT01A, VINT01J, VINT01W, OSTSPOND --> to many NAs
# X, id_revalue, ndi0, hads0_tot, hads0_anx, hads0_depr --> not used
df_pred <- df_pred %>%
dplyr::select(-c(X, id, ndi0, hads0_tot, hads0_anx, hads0_depr, VINT01A, VINT01J, VINT01W,
OSTSPOND)) %>%
mutate(ndi1_2 = as.numeric(ndi1_2)) %>%
na.omit(.) # remove NAs
# create dataframe for LM (only for time = 52 weeks)
df_pred_lm <- df_pred %>%
dplyr::filter(time_fct == 52) %>%
dplyr::select(-c(X, id, time_fct, id_revalue)) %>% # dont need these variables
na.omit(.)
# create dataframe for LM (only for time = 52 weeks)
df_pred_lm <- df_pred %>%
dplyr::filter(time_fct == 52) %>%
dplyr::select(-c(time_fct, id_revalue)) %>% # dont need these variables
na.omit(.)
# create train (80%) and test (20%) data for best subset, ridge, lasso
shuffle_ids <- sample(c(0,1), nrow(df_pred_lm), prob = c(0.5, 0.5), replace = T)
df_train <- df_pred_lm %>% filter(shuffle_ids == 0) %>% na.omit()
df_test <- df_pred_lm %>% filter(shuffle_ids == 1) %>% na.omit()
x_train <- model.matrix(ndi1_2~.,data=df_train)[,-1]
y_train <- df_train$ndi1_2
x_test <- model.matrix(ndi1_2~.,data=df_test)[,-1]
y_test <- df_test$ndi1_2
grid <- 10^seq(10,-2, length =100)
#implement the model and find the right lambda
lasso_MSE <- matrix(data=numeric(5*100),nrow=5,ncol=100)
lasso.mod <- glmnet(x_train, y_train, alpha=1, lambda=grid, standardize=TRUE)
cv.out.lasso<- cv.glmnet(x_train,y_train,alpha=1)
plot(cv.out.lasso)
log(0.3)
log(2)
bestlam.lasso <- cv.out.lasso$lambda.min
mse_lasso_CV <- numeric(5)
lasso.mod
plot(lasso.mod)
mse_lasso_CV <- numeric(5)
for(j in 1:5){
lm(ndi1_2 ~ ., data = df_pred_lm)
x_train <- model.matrix(ndi1_2~.,data= df_pred_lm[fold.index != j,])[,-1]
y_train <- na.omit(df_pred_lm[fold.index != j,]$ndi1_2)
x_test <- model.matrix(ndi1_2~.,data=df_pred_lm[fold.index == j, ])[,-1]
y_test <- na.omit(df_pred_lm[fold.index == j, ]$ndi1_2)
lasso.mod <- glmnet(x_train, y_train, alpha=1, lambda=grid, standardize=TRUE)
pred.lasso <- predict(lasso.mod,s=bestlam.lasso,newx=x_test)
mse_lasso_CV[j] <-mean((pred.lasso -y_test)^2)
}
K <- 5
index <- rep(1:K, floor(nrow(df_pred_lm)/K)+1)[1:nrow(df_pred_lm)]
fold.index <- sample(index)
table(fold.index)
mse_lasso_CV <- numeric(5)
for(j in 1:5){
lm(ndi1_2 ~ ., data = df_pred_lm)
x_train <- model.matrix(ndi1_2~.,data= df_pred_lm[fold.index != j,])[,-1]
y_train <- na.omit(df_pred_lm[fold.index != j,]$ndi1_2)
x_test <- model.matrix(ndi1_2~.,data=df_pred_lm[fold.index == j, ])[,-1]
y_test <- na.omit(df_pred_lm[fold.index == j, ]$ndi1_2)
lasso.mod <- glmnet(x_train, y_train, alpha=1, lambda=grid, standardize=TRUE)
pred.lasso <- predict(lasso.mod,s=bestlam.lasso,newx=x_test)
mse_lasso_CV[j] <-mean((pred.lasso -y_test)^2)
}
mean(mse_lasso_CV)#163.811
coef(lasso.mod, s = bestlam.lasso)
mld_lmm
summary(mld_lmm)
sqrt(0.0103)
sqrt(0.0103)/2
sqrt(0.0147)

return(rmse)
}
loss <- numeric(K)
for (k in 1:K){
training <- df_prediction[fold.index!=k, ]
validation <- df_prediction[fold.index==k, ]
training.fit <-  lmer(ndi1_2 ~ ndi0 + hads0_anx + hads0_depr + time_fct + (1|id),
data = training, REML = T)
validation.predict <- predict(training.fit, newdata=validation, type='response',
allow.new.levels = T)
loss[k] <- Loss(validation$ndi1_2, validation.predict)
}
loss
training.fit <-  lme4::lmer(ndi1_2 ~ ndi0 + hads0_anx + hads0_depr + time_fct + (1|id),
data = training, REML = T)
training <- df_prediction[fold.index!=k, ]
validation <- df_prediction[fold.index==k, ]
training.fit <-  lme4::lmer(ndi1_2 ~ ndi0 + hads0_anx + hads0_depr + time_fct + (1|id),
data = training, REML = T)
validation.predict <- predict(training.fit, newdata=validation, type='response',
allow.new.levels = T)
validation.predict
df_prediction
set.seed(19950306)
# Load libraries
rm(list = ls())
library(ggplot2)
library(lme4)
library(tidyverse)
library(nlme)
library(emmeans)
library(car)
library(lattice)
library(merTools)
library(xtable)
# Set layout for all figures
theme <- theme(panel.background = element_blank(),
panel.grid.major = element_line(colour = "darkgrey", size=0.5),
panel.grid.minor = element_line(colour = "grey",
size=.25,
linetype = "dashed"),
panel.border = element_blank(),
axis.line.x = element_line(colour = "black",
size=0.5,
lineend = "butt"),
axis.line.y = element_line(colour = "black",
size=0.5),
axis.text=element_text(size=15),
axis.title=element_text(size=22),
plot.title = element_text(size = 22),
strip.text = element_text(size = 15),
legend.title = element_blank())
df_long <- read.csv("Data/data_final_2019-11-05.csv", sep = ",")
# Some data wrangling
df_long <- df_long %>%
mutate(hads_tot = hads_depr + hads_anx) %>%
select(id, ndi, time, hads_tot, hads_anx, hads_depr) %>%
mutate(ndi = as.numeric(ndi), time = as.numeric(time),
hads_tot = as.numeric(hads_tot), time_fct = as.factor(time))
# Create new dataframe with HADS at time = 0 & NDI at time = 0
df_time0 <- df_long[df_long$time == 0, ]
df_long <- read.csv("Data/data_final_2019-11-05.csv", sep = ",")
# Some data wrangling
df_long <- df_long %>%
mutate(hads_tot = hads_depr + hads_anx) %>%
dplyr::select(id, ndi, time, hads_tot, hads_anx, hads_depr) %>%
mutate(ndi = as.numeric(ndi), time = as.numeric(time),
hads_tot = as.numeric(hads_tot), time_fct = as.factor(time))
# Create new dataframe with HADS at time = 0 & NDI at time = 0
df_time0 <- df_long[df_long$time == 0, ]
df_time0 <- select(df_time0, id, ndi, hads_tot, hads_anx, hads_depr)
# Create new dataframe with HADS at time = 0 & NDI at time = 0
df_time0 <- df_long[df_long$time == 0, ]
df_time0 <- dplyr::select(df_time0, id, ndi, hads_tot, hads_anx, hads_depr)
colnames(df_time0) <-  c("id", "ndi0", "hads0_tot", "hads0_anx", "hads0_depr")
# Create new dataframe with HADS and NDI at 52 and 104 weeks
df_time1_2 <- df_long[df_long$time != 0, ]
df_time1_2 <- select(df_time1_2, id, ndi, time_fct)
# Create new dataframe with HADS and NDI at 52 and 104 weeks
df_time1_2 <- df_long[df_long$time != 0, ]
df_time1_2 <- dplyr::select(df_time1_2, id, ndi, time_fct)
colnames(df_time1_2) <-  c("id", "ndi1_2", "time_fct")
# Merge dataframes
df_prediction <- merge(df_time1_2, df_time0, by = "id")
index <- rep(1:K, floor(nrow(df_prediction)/K)+1)[1:nrow(df_prediction)]
fold.index <- sample(index)
# Create Loss function: Root Mean Squard Error
Loss <- function(x, y){
mse <- sum((x-y)^2)/length(x)
rmse <- sqrt(mse)
return(rmse)
}
loss <- numeric(K)
# Create folds
K <- 5
index <- rep(1:K, floor(nrow(df_prediction)/K)+1)[1:nrow(df_prediction)]
fold.index <- sample(index)
# Create Loss function: Root Mean Squard Error
Loss <- function(x, y){
mse <- sum((x-y)^2)/length(x)
rmse <- sqrt(mse)
return(rmse)
}
loss <- numeric(K)
for (k in 1:K){
training <- df_prediction[fold.index!=k, ]
validation <- df_prediction[fold.index==k, ]
training.fit <-  lme4::lmer(ndi1_2 ~ ndi0 + hads0_anx + hads0_depr + time_fct + (1|id),
data = training, REML = T)
validation.predict <- predict(training.fit, newdata=validation, type='response',
allow.new.levels = T)
loss[k] <- Loss(validation$ndi1_2, validation.predict)
}
loss
round(mean(loss), digits = 1)
df_prediction
loss <- numeric(K)
for (k in 1:K){
training <- df_prediction[fold.index!=k, ]
validation <- df_prediction[fold.index==k, ]
training.fit <-  lme4::lmer(ndi1_2 ~ ndi0 + hads0_anx + hads0_depr + time_fct + (1|id),
data = df_prediction, REML = T)
validation.predict <- predict(training.fit, newdata=validation, type='response',
allow.new.levels = T)
loss[k] <- Loss(validation$ndi1_2, validation.predict)
}
loss
round(mean(loss), digits = 1)
loss <- numeric(K)
for (k in 1:K){
training <- df_prediction[fold.index!=k, ]
validation <- df_prediction[fold.index==k, ]
training.fit <-  lme4::lmer(ndi1_2 ~ ndi0 + hads0_anx + hads0_depr + time_fct + (1|id),
data = training, REML = T)
validation.predict <- predict(training.fit, newdata=validation, type='response',
allow.new.levels = T)
loss[k] <- Loss(validation$ndi1_2, validation.predict)
}
loss
round(mean(loss), digits = 1)
rm(list = ls())
library(ggplot2)
library(lme4)
library(tidyverse)
library(nlme)
library(emmeans)
library(car)
library(lattice)
library(xtable)
library(gridExtra)
ggCaterpillar <- function(re, QQ=TRUE, likeDotplot=TRUE) {
require(ggplot2)
f <- function(x) {
pv   <- attr(x, "postVar")
cols <- 1:(dim(pv)[1])
se   <- unlist(lapply(cols, function(i) sqrt(pv[i, i, ])))
ord  <- unlist(lapply(x, order)) + rep((0:(ncol(x) - 1)) * nrow(x), each=nrow(x))
pDf  <- data.frame(y=unlist(x)[ord],
ci=1.96*se[ord],
nQQ=rep(qnorm(ppoints(nrow(x))), ncol(x)),
ID=factor(rep(rownames(x), ncol(x))[ord], levels=rownames(x)[ord]),
ind=gl(ncol(x), nrow(x), labels=names(x)))
if(QQ) {  ## normal QQ-plot
p <- ggplot(pDf, aes(nQQ, y))
p <- p + facet_wrap(~ ind, scales="free")
p <- p + xlab("Standard normal quantiles") + ylab("Random effect quantiles")
} else {  ## caterpillar dotplot
p <- ggplot(pDf, aes(ID, y)) + coord_flip()
if(likeDotplot) {  ## imitate dotplot() -> same scales for random effects
p <- p + facet_wrap(~ ind)
} else {           ## different scales for random effects
p <- p + facet_grid(ind ~ ., scales="free_y")
}
p <- p + xlab("Levels") + ylab("Random effects")
}
p <- p + theme(legend.position="none")
p <- p + geom_hline(yintercept=0)
p <- p + geom_errorbar(aes(ymin=y-ci, ymax=y+ci), width=0, colour="black")
p <- p + geom_point(aes(size=1.2), colour="blue")
return(p)
}
lapply(re, f)
}
# Set layout for all figures
theme <- theme(panel.background = element_blank(),
panel.grid.major = element_line(colour = "darkgrey", size=0.5),
panel.grid.minor = element_line(colour = "grey",
size=.25,
linetype = "dashed"),
panel.border = element_blank(),
axis.line.x = element_line(colour = "black",
size=0.5,
lineend = "butt"),
axis.line.y = element_line(colour = "black",
size=0.5),
axis.text=element_text(size=15),
axis.title=element_text(size=22),
plot.title = element_text(size = 22),
strip.text = element_text(size = 15),
legend.title = element_blank())
df_long <- read.csv("Data/data_final_2019-11-05.csv", sep = ",")
df_long <- df_long %>%
mutate(hads_tot = hads_depr + hads_anx) %>%
select(id, ndi, time, hads_tot, hads_anx, hads_depr ) %>%
mutate(ndi = as.numeric(ndi), time = as.numeric(time),
hads_tot = as.numeric(hads_tot), time_fct = as.factor(time))
vif(model5)
model5 <- nlme::lme(ndi ~ time_fct + hads_anx + hads_depr, random = ~1|id, method= "ML",
data = df_long)
d
vif(model5)
#model_final <- nlme::lme(ndi ~ time + hads_tot, random = ~1|id, method= "REML", data = df_long)
model_final <- nlme::lme(ndi ~ time_fct + hads_anx + hads_depr, method = "REML",
random = ~1|id, data = df_long)
summary(model_final)
final_mod_summ <- coef(summary(model_final))
xtable(final_mod_summ)
# Calculate the intra class correlation:
# Model explains only 47.3 % of variance
random_effects <- VarCorr(model_final)
print(random_effects,comp=c("Variance"))
80.90435 / (80.90435 + 90.19087)
# Create folds
K <- 5
index <- rep(1:K, floor(nrow(df_long)/K)+1)[1:nrow(df_long)]
fold.index <- sample(index)
# Create Loss function: Root Mean Squard Error
Loss <- function(x, y){
mse <- sum((x-y)^2)/length(x)
rmse <- sqrt(mse)
return(rmse)
}
loss <- numeric(K)
for (k in 1:K){
training <- df_long[fold.index!=k, ]
validation <- df_long[fold.index==k, ]
training.fit <- model_final <- nlme::lme(ndi ~ time_fct + hads_anx + hads_depr, method = "REML",
random = ~1|id, data = training)
validation.predict <- predict(training.fit, newdata=validation, type='response')
loss[k] <- Loss(validation$ndi, validation.predict)
}
loss
training <- df_long[fold.index!=k, ]
validation <- df_long[fold.index==k, ]
training.fit <- model_final <- nlme::lme(ndi ~ time_fct + hads_anx + hads_depr, method = "REML",
random = ~1|id, data = training)
validation.predict <- predict(training.fit, newdata=validation, type='response')
validation.predict
loss[k] <- Loss(validation$ndi, validation.predict)
loss
# Create folds
K <- 5
index <- rep(1:K, floor(nrow(df_long)/K)+1)[1:nrow(df_long)]
fold.index <- sample(index)
# Create Loss function: Root Mean Squard Error
Loss <- function(x, y){
mse <- sum((x-y)^2)/length(x)
rmse <- sqrt(mse)
return(rmse)
}
# Create Loss function: Root Mean Squard Error
Loss <- function(x, y){
mse <- sum((x-y)^2)/length(x)
rmse <- sqrt(mse)
return(rmse)
}
loss <- numeric(K)
for (k in 1:K){
training <- df_long[fold.index!=k, ]
validation <- df_long[fold.index==k, ]
training.fit <- nlme::lme(ndi ~ time_fct + hads_anx + hads_depr, method = "REML",
random = ~1|id, data = training)
validation.predict <- predict(training.fit, newdata=validation, type='response')
loss[k] <- Loss(validation$ndi, validation.predict)
}
loss
training.fit
Loss(validation$ndi, validation.predict)
predict(training.fit, newdata=validation, type='response')
Loss(validation$ndi, validation.predict)
validation$ndi
validation.predict
loss <- numeric(K)
for (k in 1:K){
training <- df_long[fold.index!=k, ]
validation <- df_long[fold.index==k, ]
training.fit <- nlme::lme(ndi ~ time_fct + hads_anx + hads_depr, method = "REML",
random = ~1|id, data = training, allow.new.levels = T)
validation.predict <- predict(training.fit, newdata=validation, type='response')
loss[k] <- Loss(validation$ndi, validation.predict)
}
predict(training.fit, newdata=validation, type='response',
allow.new.levels = T)
validation.predict
validation$ndi
validation$ndi - validation.predict
training <- df_long[fold.index!=k, ]
validation <- df_long[fold.index==k, ]
training.fit <- nlme::lme(ndi ~ time_fct + hads_anx + hads_depr, method = "REML",
random = ~1|id, data = training)
validation.predict <- predict(training.fit, newdata=validation, type='response',
allow.new.levels = T)
loss[k] <- Loss(validation$ndi, validation.predict)
loss
Loss(validation$ndi, validation.predict)
validation.predict
training.fit <- lme4::lmer(ndi ~  time_fct + hads_anx + hads_depr + (1|id),
data = training, REML = T)
validation.predict <- predict(training.fit, newdata=validation, type='response',
allow.new.levels = T)
loss[k] <- Loss(validation$ndi, validation.predict)
loss
# Create folds
K <- 5
index <- rep(1:K, floor(nrow(df_long)/K)+1)[1:nrow(df_long)]
fold.index <- sample(index)
# Create Loss function: Root Mean Squard Error
Loss <- function(x, y){
mse <- sum((x-y)^2)/length(x)
rmse <- sqrt(mse)
return(rmse)
}
loss <- numeric(K)
for (k in 1:K){
training <- df_long[fold.index!=k, ]
validation <- df_long[fold.index==k, ]
training.fit <- lme4::lmer(ndi ~  time_fct + hads_anx + hads_depr + (1|id),
data = training, REML = T)
validation.predict <- predict(training.fit, newdata=validation, type='response',
allow.new.levels = T)
loss[k] <- Loss(validation$ndi, validation.predict)
}
loss
mean(loss)
model_final <- nlme::lme(ndi1_2 ~ ndi0 + hads0_anx + hads0_depr + time_fct, method = "REML",
random = ~1|id, data = df_prediction)
model_final2 <- nlme::lme(ndi1_2 ~ ndi0 + hads0_anx + time_fct, method = "REML",
random = ~1|id, data = df_prediction)
# Load libraries
rm(list = ls())
library(ggplot2)
library(lme4)
library(tidyverse)
library(nlme)
library(emmeans)
library(car)
library(lattice)
library(merTools)
library(xtable)
# Set layout for all figures
theme <- theme(panel.background = element_blank(),
panel.grid.major = element_line(colour = "darkgrey", size=0.5),
panel.grid.minor = element_line(colour = "grey",
size=.25,
linetype = "dashed"),
panel.border = element_blank(),
axis.line.x = element_line(colour = "black",
size=0.5,
lineend = "butt"),
axis.line.y = element_line(colour = "black",
size=0.5),
axis.text=element_text(size=15),
axis.title=element_text(size=22),
plot.title = element_text(size = 22),
strip.text = element_text(size = 15),
legend.title = element_blank())
df_long <- read.csv("Data/data_final_2019-11-05.csv", sep = ",")
# Some data wrangling
df_long <- df_long %>%
mutate(hads_tot = hads_depr + hads_anx) %>%
dplyr::select(id, ndi, time, hads_tot, hads_anx, hads_depr) %>%
mutate(ndi = as.numeric(ndi), time = as.numeric(time),
hads_tot = as.numeric(hads_tot), time_fct = as.factor(time))
# Create new dataframe with HADS at time = 0 & NDI at time = 0
df_time0 <- df_long[df_long$time == 0, ]
df_time0 <- dplyr::select(df_time0, id, ndi, hads_tot, hads_anx, hads_depr)
colnames(df_time0) <-  c("id", "ndi0", "hads0_tot", "hads0_anx", "hads0_depr")
# Create new dataframe with HADS and NDI at 52 and 104 weeks
df_time1_2 <- df_long[df_long$time != 0, ]
df_time1_2 <- dplyr::select(df_time1_2, id, ndi, time_fct)
colnames(df_time1_2) <-  c("id", "ndi1_2", "time_fct")
# Merge dataframes
df_prediction <- merge(df_time1_2, df_time0, by = "id")
model_final <- nlme::lme(ndi1_2 ~ ndi0 + hads0_anx + hads0_depr + time_fct, method = "REML",
random = ~1|id, data = df_prediction)
model_final2 <- nlme::lme(ndi1_2 ~ ndi0 + hads0_anx + time_fct, method = "REML",
random = ~1|id, data = df_prediction)
anova(model_final, model_final2)
model_final <- nlme::lme(ndi1_2 ~ ndi0 + hads0_anx + hads0_depr + time_fct, method = "ML",
random = ~1|id, data = df_prediction)
model_final2 <- nlme::lme(ndi1_2 ~ ndi0 + hads0_anx + time_fct, method = "ML",
random = ~1|id, data = df_prediction)
anova(model_final, model_final2)
anova(model_final2, model_final)
model_final3 <- nlme::lme(ndi1_2 ~ ndi0 + time_fct, method = "ML",
random = ~1|id, data = df_prediction)
anova(model_final2, model_final3)
model_final4 <- nlme::lme(ndi1_2 ~ ndi0, method = "ML",
random = ~1|id, data = df_prediction)
anova(model_final4, model_final3)
summary(model_final3)
summary(model_final4)
rm(list = ls())
library(ggplot2)
library(lme4)
library(tidyverse)
library(nlme)
library(emmeans)
library(car)
library(lattice)
library(xtable)
library(gridExtra)
ggCaterpillar <- function(re, QQ=TRUE, likeDotplot=TRUE) {
require(ggplot2)
f <- function(x) {
pv   <- attr(x, "postVar")
cols <- 1:(dim(pv)[1])
se   <- unlist(lapply(cols, function(i) sqrt(pv[i, i, ])))
ord  <- unlist(lapply(x, order)) + rep((0:(ncol(x) - 1)) * nrow(x), each=nrow(x))
pDf  <- data.frame(y=unlist(x)[ord],
ci=1.96*se[ord],
nQQ=rep(qnorm(ppoints(nrow(x))), ncol(x)),
ID=factor(rep(rownames(x), ncol(x))[ord], levels=rownames(x)[ord]),
ind=gl(ncol(x), nrow(x), labels=names(x)))
if(QQ) {  ## normal QQ-plot
p <- ggplot(pDf, aes(nQQ, y))
p <- p + facet_wrap(~ ind, scales="free")
p <- p + xlab("Standard normal quantiles") + ylab("Random effect quantiles")
} else {  ## caterpillar dotplot
p <- ggplot(pDf, aes(ID, y)) + coord_flip()
if(likeDotplot) {  ## imitate dotplot() -> same scales for random effects
p <- p + facet_wrap(~ ind)
} else {           ## different scales for random effects
p <- p + facet_grid(ind ~ ., scales="free_y")
}
p <- p + xlab("Levels") + ylab("Random effects")
}
p <- p + theme(legend.position="none")
p <- p + geom_hline(yintercept=0)
p <- p + geom_errorbar(aes(ymin=y-ci, ymax=y+ci), width=0, colour="black")
p <- p + geom_point(aes(size=1.2), colour="blue")
return(p)
}
lapply(re, f)
}
# Set layout for all figures
theme <- theme(panel.background = element_blank(),
panel.grid.major = element_line(colour = "darkgrey", size=0.5),
panel.grid.minor = element_line(colour = "grey",
size=.25,
linetype = "dashed"),
panel.border = element_blank(),
axis.line.x = element_line(colour = "black",
size=0.5,
lineend = "butt"),
axis.line.y = element_line(colour = "black",
size=0.5),
axis.text=element_text(size=15),
axis.title=element_text(size=22),
plot.title = element_text(size = 22),
strip.text = element_text(size = 15),
legend.title = element_blank())
df_long <- read.csv("Data/data_final_2019-11-05.csv", sep = ",")
df_long <- df_long %>%
mutate(hads_tot = hads_depr + hads_anx) %>%
select(id, ndi, time, hads_tot, hads_anx, hads_depr ) %>%
mutate(ndi = as.numeric(ndi), time = as.numeric(time),
hads_tot = as.numeric(hads_tot), time_fct = as.factor(time))
model1 <- nlme::lme(ndi ~ time_fct, random = ~1|id, method= "ML", data = df_long)
model2 <- nlme::lme(ndi ~ time_fct + hads_anx, random = ~1|id, method= "ML", data = df_long)
summary(model2)
summary(model3)
model3 <- nlme::lme(ndi ~ time_fct + hads_depr, random = ~1|id, method= "ML",
data = df_long)
summary(model3)
model5 <- nlme::lme(ndi ~ time_fct + hads_anx + hads_depr, random = ~1|id, method= "ML",
data = df_long)
refgrid <-  ref_grid(model_final)
refgrid
#model_final <- nlme::lme(ndi ~ time + hads_tot, random = ~1|id, method= "REML", data = df_long)
model_final <- nlme::lme(ndi ~ time_fct + hads_anx + hads_depr, method = "REML",
random = ~1|id, data = df_long)
refgrid <-  ref_grid(model_final)
refgrid
df_emmeans <-  data.frame(summary(refgrid))
df_emmeans$time <- as.numeric(as.character(df_emmeans$time_fct))
df_emmeans$lwr <- df_emmeans$prediction - 1.96*df_emmeans$SE
df_emmeans$upr <- df_emmeans$prediction + 1.96*df_emmeans$SE
p3 <- ggplot(data = df_emmeans, aes(x = time, y = prediction )) + geom_point() +
geom_line(col = "blue", size = 2) +
geom_point(col = "blue", size = 4) +
geom_ribbon(data=df_emmeans, aes(ymin= lwr, ymax= upr), alpha=0.3) +
theme(legend.position = "none") +
ylab("NDI")  +
xlab("Time (weeks)") + theme
p3 <- ggplot(data = df_emmeans, aes(x = time, y = prediction )) + geom_point() +
geom_line(col = "blue", size = 2) +
geom_point(col = "blue", size = 4) +
geom_ribbon(data=df_emmeans, aes(ymin= lwr, ymax= upr), alpha=0.3) +
theme(legend.position = "none") +
ylab("NDI")  + ylim(c(0,50))
p3 <- ggplot(data = df_emmeans, aes(x = time, y = prediction )) + geom_point() +
geom_line(col = "blue", size = 2) +
geom_point(col = "blue", size = 4) +
geom_ribbon(data=df_emmeans, aes(ymin= lwr, ymax= upr), alpha=0.3) +
theme(legend.position = "none") +
ylab("NDI")  + ylim(c(0,50)) +
xlab("Time (weeks)") + theme
plot(p3)
png("Figures/Marginal_NDI.png",width = 15, height = 7, units='in',res=300)
plot(p3)
dev.off()
